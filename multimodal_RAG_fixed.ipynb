{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973de2d3",
   "metadata": {},
   "source": [
    "# Multimodal RAG (PDF with Images) ‚Äî Gemini Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f020d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "PDF path: M:\\job hunt\\Harrisburg University Documents\\ML Project\\Kris_Naik_series_Projects\\Multimodal RAG\\The 2025 AI Engineering Report _ Amplify Partners.pdf\n"
     ]
    }
   ],
   "source": [
    "# === Imports & Config ===\n",
    "import os, io, base64\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# CONFIG ‚Äî EDIT OR SET VIA .env\n",
    "pdf_path = os.getenv(\"PDF_PATH\")  # <-- set your PDF path\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PDF path: {pdf_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbf744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "### CLIP MODEL ‚Äî Contrastive Language Image PreTraining\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model.eval()  # IMPORTANT: put model in eval mode\n",
    "\n",
    "def _normalize_torch(v: torch.Tensor) -> torch.Tensor:\n",
    "    return v / (v.norm(dim=-1, keepdim=True) + 1e-8)\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_image(image_data) -> np.ndarray:\n",
    "    \"\"\"Embed an image with CLIP and return a normalized numpy vector.\"\"\"\n",
    "    if isinstance(image_data, str):  # path\n",
    "        image = Image.open(image_data).convert(\"RGB\")\n",
    "    elif isinstance(image_data, (bytes, bytearray)):\n",
    "        image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "    elif isinstance(image_data, Image.Image):\n",
    "        image = image_data.convert(\"RGB\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported image_data type for embed_image\")\n",
    "\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    feats = clip_model.get_image_features(**inputs)\n",
    "    feats = _normalize_torch(feats).squeeze(0).detach().cpu().numpy()\n",
    "    return feats\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_text(text: str) -> np.ndarray:\n",
    "    \"\"\"Embed text with CLIP and return a normalized numpy vector.\"\"\"\n",
    "    inputs = clip_processor(\n",
    "        text=text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=77  # CLIP's text limit\n",
    "    ).to(device)\n",
    "    feats = clip_model.get_text_features(**inputs)\n",
    "    feats = _normalize_torch(feats).squeeze(0).detach().cpu().numpy()\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b692a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process PDF\n",
    "assert os.path.exists(pdf_path), f\"PDF not found: {pdf_path}\"\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "## Storage for all documents and embeddings\n",
    "all_docs = []               # will store langchain Document objects (text + image markers)\n",
    "all_embeddings = []         # numpy vectors aligned with all_docs\n",
    "image_data_store = {}       # {image_id: base64_png} for multimodal LLM input\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b9daf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 70 | Embeddings shape: (70, 512)\n"
     ]
    }
   ],
   "source": [
    "for i, page in enumerate(doc):\n",
    "    ## process text\n",
    "    text = page.get_text() or \"\"\n",
    "    if text.strip():\n",
    "        temp_doc = Document(page_content=text, metadata={\"page\": i, \"type\": \"text\"})\n",
    "        # Some LangChain versions use split_documents; older used split_document\n",
    "        try:\n",
    "            text_chunks = splitter.split_documents([temp_doc])  # standard\n",
    "        except AttributeError:\n",
    "            text_chunks = splitter.split_document([temp_doc])   # compat\n",
    "\n",
    "        # Embed each chunk using CLIP\n",
    "        for chunk in text_chunks:\n",
    "            embedding = embed_text(chunk.page_content)\n",
    "            all_docs.append(chunk)\n",
    "            all_embeddings.append(embedding)\n",
    "\n",
    "    ## process images\n",
    "    for img_index, img in enumerate(page.get_images(full=True)):\n",
    "        try:\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "\n",
    "            # Convert to PIL and store as base64 PNG for LLM\n",
    "            pil_image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "            buffered = io.BytesIO()\n",
    "            pil_image.save(buffered, format=\"PNG\")\n",
    "            img_base64 = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "            image_id = f\"page_{i}_img_{img_index}\"\n",
    "            image_data_store[image_id] = img_base64\n",
    "\n",
    "            # Embed the image\n",
    "            embedding = embed_image(pil_image)\n",
    "\n",
    "            # Create a lightweight doc to pair with the embedding\n",
    "            image_doc = Document(\n",
    "                page_content=f\"[Image:{image_id}]\",\n",
    "                metadata={\"page\": i, \"type\": \"image\", \"image_id\": image_id}\n",
    "            )\n",
    "            all_docs.append(image_doc)\n",
    "            all_embeddings.append(embedding)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_index} on page {i}: {e}\")\n",
    "\n",
    "doc.close()\n",
    "\n",
    "# Build embedding matrix (N x D), D=512 for CLIP ViT-B/32\n",
    "emb_matrix = np.vstack(all_embeddings) if all_embeddings else np.zeros((0, 512))\n",
    "print(f\"Docs: {len(all_docs)} | Embeddings shape: {emb_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f68cb49",
   "metadata": {},
   "source": [
    "## Retrivers Helpers (search + quick viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "809141af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieval helpers\n",
    "def _cos_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    a_n = a / (np.linalg.norm(a) + 1e-8)\n",
    "    b_n = b / (np.linalg.norm(b) + 1e-8)\n",
    "    return float(np.dot(a_n, b_n))\n",
    "\n",
    "def search(query_text=None, query_image=None, top_k=5):\n",
    "    assert (query_text is not None) ^ (query_image is not None), \"Provide either query_text or query_image\"\n",
    "    if emb_matrix.shape[0] == 0:\n",
    "        return []\n",
    "\n",
    "    # Build query vector\n",
    "    if query_text is not None:\n",
    "        q = embed_text(query_text)\n",
    "    else:\n",
    "        if isinstance(query_image, (bytes, bytearray)):\n",
    "            query_image = Image.open(io.BytesIO(query_image)).convert(\"RGB\")\n",
    "        q = embed_image(query_image)\n",
    "\n",
    "    # Cosine similarity via pre-normalized trick\n",
    "    q_n = q / (np.linalg.norm(q) + 1e-8)\n",
    "    sims = emb_matrix @ q_n  # (N, D) @ (D,) -> (N,)\n",
    "\n",
    "    idx = np.argsort(-sims)[:top_k]\n",
    "    return [(float(sims[i]), all_docs[i]) for i in idx]\n",
    "\n",
    "def show_matches(results):\n",
    "    for score, d in results:\n",
    "        kind = d.metadata.get(\"type\")\n",
    "        page = d.metadata.get(\"page\")\n",
    "        if kind == \"text\":\n",
    "            snippet = d.page_content.replace(\"\\n\", \" \")[:320]\n",
    "            print(f\"[{score:.3f}] page {page} :: {snippet}...\")\n",
    "        else:\n",
    "            print(f\"[{score:.3f}] page {page} :: [image] {d.metadata.get('image_id')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aaddb9",
   "metadata": {},
   "source": [
    "## Gemini-1.5 Multimodal Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa4135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gemini 1.5 Answer (multimodal)\n",
    "def _answer_gemini(question: str, context: str, image_payloads_b64):\n",
    "    \"\"\"\n",
    "    image_payloads_b64: list of dicts like {\"mime_type\": \"image/png\", \"image_data\": \"<base64str>\"}\n",
    "    We convert them to PIL.Image for the Gemini SDK.\n",
    "    \"\"\"\n",
    "    import google.generativeai as genai\n",
    "    api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "    assert api_key, \"GOOGLE_API_KEY not set. Put it in your .env or os.environ.\"\n",
    "\n",
    "    genai.configure(api_key=api_key)\n",
    "    model_name = os.getenv(\"GEMINI_MODEL\", \"gemini-1.5-flash\")\n",
    "    model = genai.GenerativeModel(model_name)\n",
    "\n",
    "    # Build prompt (keep it grounded in retrieved context)\n",
    "    sys_text = (\n",
    "        \"You are a concise, helpful assistant. \"\n",
    "        \"Use ONLY the provided context. If the answer is not in the context, say you don't know.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    )\n",
    "\n",
    "    # Convert base64 ‚Üí PIL for Gemini\n",
    "    from PIL import Image\n",
    "    imgs = []\n",
    "    for p in image_payloads_b64[:4]:  # limit to keep request light\n",
    "        try:\n",
    "            if p.get(\"mime_type\",\"\").startswith(\"image/\") and p.get(\"image_data\"):\n",
    "                img_bytes = base64.b64decode(p[\"image_data\"])\n",
    "                imgs.append(Image.open(io.BytesIO(img_bytes)).convert(\"RGB\"))\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Send as mixed parts: text first, then images\n",
    "    parts = [sys_text] + imgs\n",
    "    resp = model.generate_content(parts, safety_settings=None)\n",
    "    try:\n",
    "        return resp.text.strip()\n",
    "    except Exception:\n",
    "        return str(resp)\n",
    "\n",
    "def answer(question: str, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    RAG answer flow:\n",
    "    1) Retrieve top_k relevant chunks/images.\n",
    "    2) Build text context from chunks + attach some images.\n",
    "    3) Ask Gemini. If Gemini isn't configured, return fallback with matches.\n",
    "    \"\"\"\n",
    "    results = search(query_text=question, top_k=top_k)\n",
    "\n",
    "    # 1) Build text context & image payloads from retrieval\n",
    "    ctx_bits, image_payloads = [], []\n",
    "    for score, d in results:\n",
    "        if d.metadata.get(\"type\") == \"text\":\n",
    "            snippet = d.page_content.strip().replace(\"\\n\", \" \")\n",
    "            ctx_bits.append(f\"[p{d.metadata.get('page','?')}] {snippet}\")\n",
    "        elif d.metadata.get(\"type\") == \"image\":\n",
    "            image_id = d.metadata.get(\"image_id\")\n",
    "            if image_id and image_id in image_data_store:\n",
    "                image_payloads.append({\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_data\": image_data_store[image_id],\n",
    "                    \"mime_type\": \"image/png\",\n",
    "                })\n",
    "\n",
    "    context = \"\\n\".join(ctx_bits[:10])  # trim to keep prompt lean\n",
    "\n",
    "    # 2) Try Gemini; if not available, return a fallback\n",
    "    try:\n",
    "        ans = _answer_gemini(question, context, image_payloads)\n",
    "        return {\"answer\": ans, \"matches\": results, \"provider\": \"gemini\"}\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"answer\": f\"(LLM unavailable) {e}\\nTop matches shown below.\",\n",
    "            \"matches\": results,\n",
    "            \"provider\": None\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c88371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this under your existing LLM wiring cell\n",
    "def answer_charts_ok(question: str, top_k: int = 12, max_imgs: int = 6):\n",
    "    # 1) retrieve (hybrid preferred, else CLIP-only)\n",
    "    try:\n",
    "        results = search_hybrid(query_text=question, top_k=top_k)\n",
    "    except NameError:\n",
    "        results = search(query_text=question, top_k=top_k)\n",
    "\n",
    "    # 2) collect text + images\n",
    "    ctx_bits, image_payloads = [], []\n",
    "    img_count = 0\n",
    "    for score, d in results:\n",
    "        if d.metadata.get(\"type\") == \"text\":\n",
    "            snippet = d.page_content.strip().replace(\"\\n\", \" \")\n",
    "            ctx_bits.append(f\"[p{d.metadata.get('page','?')}] {snippet}\")\n",
    "        elif d.metadata.get(\"type\") == \"image\" and img_count < max_imgs:\n",
    "            img_id = d.metadata.get(\"image_id\")\n",
    "            if img_id and img_id in image_data_store:\n",
    "                image_payloads.append({\n",
    "                    \"type\":\"input_image\",\n",
    "                    \"image_data\": image_data_store[img_id],\n",
    "                    \"mime_type\":\"image/png\"\n",
    "                })\n",
    "                img_count += 1\n",
    "    context = \"\\n\".join(ctx_bits[:10])\n",
    "\n",
    "    # 3) chart-aware Gemini call\n",
    "    def _answer_gemini_charts(q, ctx, imgs):\n",
    "        import google.generativeai as genai, os, base64, io\n",
    "        from PIL import Image\n",
    "        genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "        model = genai.GenerativeModel(os.getenv(\"GEMINI_MODEL\",\"gemini-1.5-flash\"))\n",
    "\n",
    "        sys_text = (\n",
    "            \"You will see numeric tables and charts. Read them carefully.\\n\"\n",
    "            \"Summarize the key findings and trends using only the provided content.\\n\"\n",
    "            \"Prioritize charts/tables if narrative text is limited. Cite page numbers in brackets.\\n\\n\"\n",
    "            f\"Context (text snippets):\\n{ctx}\\n\\nQuestion: {q}\\nAnswer:\"\n",
    "        )\n",
    "\n",
    "        images = []\n",
    "        for p in imgs[:6]:\n",
    "            try:\n",
    "                img_bytes = base64.b64decode(p[\"image_data\"])\n",
    "                images.append(Image.open(io.BytesIO(img_bytes)).convert(\"RGB\"))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        parts = [sys_text] + images\n",
    "        resp = model.generate_content(parts, safety_settings=None)\n",
    "        try:\n",
    "            return resp.text.strip()\n",
    "        except Exception:\n",
    "            return str(resp)\n",
    "\n",
    "    try:\n",
    "        ans = _answer_gemini_charts(question, context, image_payloads)\n",
    "        return {\"answer\": ans, \"matches\": results, \"provider\": \"gemini\"}\n",
    "    except Exception as e:\n",
    "        return {\"answer\": f\"(LLM unavailable) {e}\", \"matches\": results, \"provider\": None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09c4c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_many(questions, use_charts=False, top_k=8, max_imgs=6, save_csv=None):\n",
    "    \"\"\"\n",
    "    Ask multiple questions, print answers + top matches, and optionally save a CSV.\n",
    "    - use_charts=True    -> uses answer_charts_ok (better for table/chart-heavy PDFs)\n",
    "    - use_charts=False   -> uses answer (better for narrative PDFs)\n",
    "    \"\"\"\n",
    "    fn = answer_charts_ok if use_charts else answer\n",
    "    rows = []\n",
    "    for q in questions:\n",
    "        resp = fn(q, top_k=top_k) if not use_charts else fn(q, top_k=top_k, max_imgs=max_imgs)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"Q:\", q)\n",
    "        print(\"\\n--- Answer ---\")\n",
    "        print(resp[\"answer\"])\n",
    "        print(\"\\n--- Top matches ---\")\n",
    "        show_matches(resp[\"matches\"])\n",
    "\n",
    "        pages = []\n",
    "        for score, d in resp[\"matches\"]:\n",
    "            p = d.metadata.get(\"page\")\n",
    "            if isinstance(p, int):\n",
    "                pages.append(p)\n",
    "        rows.append({\"question\": q, \"answer\": resp[\"answer\"], \"pages_topk\": pages[:top_k]})\n",
    "\n",
    "    if save_csv:\n",
    "        try:\n",
    "            import pandas as pd, csv\n",
    "            pd.DataFrame(rows).to_csv(save_csv, index=False, quoting=csv.QUOTE_MINIMAL)\n",
    "            print(f\"\\nSaved: {save_csv}\")\n",
    "        except Exception as e:\n",
    "            print(\"CSV save skipped:\", e)\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec9308",
   "metadata": {},
   "source": [
    "## A quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2602bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY set: True\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. List section headings with page numbers.\n",
      "\n",
      "--- Answer ---\n",
      "Here's a summary of the provided text, organized by section headings and page numbers:\n",
      "\n",
      "**[p2] AI Engineering Experience:** Many seasoned developers are new to AI; 45% of respondents with 10+ years of software experience have 3 years or fewer of AI experience, and 1 in 10 have less than 1 year.\n",
      "\n",
      "**[p9] Model Updates:**  New models are released frequently, with over 50% of respondents updating their models monthly, and 17% weekly.\n",
      "\n",
      "**[p13] Other Modalities:** Usage of audio, image, and video lags significantly behind text.\n",
      "\n",
      "**[p15] Image Generation:** Image generation is the most popular among other modalities (audio, image, video).\n",
      "\n",
      "**[p18] Agents:**  Agents (LLM-controlled systems) are nascent; 80% of respondents say LLMs work well, but less than 20% say the same about agents. Fewer than 1 in 10 have no plans to use agents.\n",
      "\n",
      "**[p19] Agent Permissions:**  Most respondents with agents in production have write data capabilities, but with human oversight; 13% have fully independent action capabilities.\n",
      "\n",
      "**[p26] Painful Aspects of AI Engineering:** The report asked about the most painful aspect of AI engineering today, but the answer isn't provided.\n",
      "\n",
      "**[p27] Learning Resources:**  The report mentions podcasts and newsletters used for AI engineering learning.  There's bias due to partnership with Latent Space.\n",
      "\n",
      "**[p31] Thoughts:** This section contains various thoughts, including that agents are workflows and considerations for hiring.\n",
      "\n",
      "--- Top matches ---\n",
      "[0.811] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.799] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.795] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.788] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.787] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.779] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.775] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.774] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.762] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "[0.760] page 15 :: most popular among these modalities. Starting with image generation: 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 16/32...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Extract 7 key findings with exact % and dates.\n",
      "\n",
      "--- Answer ---\n",
      "Here are seven key findings from the provided text, including percentages and dates:\n",
      "\n",
      "1. More than 50% of respondents update their models at least monthly, with 17% doing so weekly. [p9]  8/10/25\n",
      "2. 80% of respondents say LLMs are working well at work, but less than 20% say the same about agents. [p18] 8/10/25\n",
      "3. Fewer than 1 in 10 respondents say they have no plans to use agents at all. [p18] 8/10/25\n",
      "4. The majority of respondents with agents in production have the ability to write data, albeit with a human in the loop; 13% can take actions completely independently. [p19] 8/10/25\n",
      "5. Of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. [p2] 8/10/25\n",
      "6. 1 in 10 respondents have less than 1 year of AI experience. [p2] 8/10/25\n",
      "7. More than half of respondents indicated they‚Äôre using LLMs for both [the text cuts off here, preventing completion of this point]. [p3] 8/10/25\n",
      "\n",
      "--- Top matches ---\n",
      "[0.827] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.805] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.801] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.796] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.788] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.785] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.780] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.775] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.774] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "[0.772] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. How often do teams update models? Give % weekly/monthly + reasons.\n",
      "\n",
      "--- Answer ---\n",
      "More than 50% of respondents update their models at least monthly, with 17% doing so weekly [p9].  The reason given is that new models with better benchmarks and breaking changes are released every week, sometimes literally [p9].\n",
      "\n",
      "--- Top matches ---\n",
      "[0.837] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.804] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.788] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.785] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "[0.785] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.778] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.769] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.765] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.765] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "[0.764] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Compare effectiveness of LLMs vs agents; include definitions if given.\n",
      "\n",
      "--- Answer ---\n",
      "In 2025, 80% of respondents said LLMs were working well at work, [p18] while less than 20% said the same about agents. [p18]  The survey defined an agent as \"a system where the LLM controls the core decision making or workflow.\" [p18]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.826] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.808] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.800] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.794] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.776] page 6 :: Another important story here is heterogeneity. 94% of people using LLMs are using them for at least 2 use cases, and 82% are using them for at least 3.¬† Essentially: folks using LLMs are using them internally, externally, and across multiple use cases. 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners ...\n",
      "[0.774] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.771] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "[0.769] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.767] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.767] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. What share won‚Äôt pay more for lower latency/better reasoning? Any cuts by size?\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 29\n",
      "}\n",
      "]\n",
      "Top matches shown below.\n",
      "\n",
      "--- Top matches ---\n",
      "[0.847] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.838] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.826] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.818] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.817] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.812] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.811] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.808] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.804] page 6 :: Another important story here is heterogeneity. 94% of people using LLMs are using them for at least 2 use cases, and 82% are using them for at least 3.¬† Essentially: folks using LLMs are using them internally, externally, and across multiple use cases. 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners ...\n",
      "[0.803] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Most used tools (vector DBs/orchestration/eval) with any %.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 29\n",
      "}\n",
      "]\n",
      "Top matches shown below.\n",
      "\n",
      "--- Top matches ---\n",
      "[0.826] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.800] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.797] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.796] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.795] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.793] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.793] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.791] page 22 :: Storage, retrieval, and üåüvector databases üåü Where does the context live? How do we get it when we need it? 65% of respondents are using a dedicated vector database. It turns out that at the moment specialized 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/t...\n",
      "[0.781] page 23 :: vector databases are providing enough value over general purpose ones with vector extensions. 35% said they primarily self host, while 30% primarily use a third party provider. But overall, that‚Äôs a healthy majority!¬† The (more) fun stuff 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.am...\n",
      "[0.773] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. How do teams evaluate models (offline/online, metrics, examples)?\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 29\n",
      "}\n",
      "]\n",
      "Top matches shown below.\n",
      "\n",
      "--- Top matches ---\n",
      "[0.816] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.805] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.793] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "[0.789] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.787] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.769] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.768] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.768] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.767] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.764] page 21 :: We asked the same question for how they evaluate model and system accuracy. Folks are using a combination of methods, including data collection from users, benchmarking, etc. But the most popular at the end of the day is still human review. What about monitoring your own model usage? Most respondents rely on internal m...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Deployment targets (cloud/on-prem/edge) and motives with %.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 29\n",
      "}\n",
      "]\n",
      "Top matches shown below.\n",
      "\n",
      "--- Top matches ---\n",
      "[0.791] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.789] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.787] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.772] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "[0.771] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.763] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.761] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.756] page 22 :: Storage, retrieval, and üåüvector databases üåü Where does the context live? How do we get it when we need it? 65% of respondents are using a dedicated vector database. It turns out that at the moment specialized 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/t...\n",
      "[0.752] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.751] page 4 :: internal and external use cases.¬† The top use cases we‚Äôre seeing overall are squarely for developers ‚Äì code generation and code intelligence ‚Äì but there‚Äôs also a good deal of writing related tasks in there too.¬† 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-post...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Grounding data sources; % and challenges.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "Top matches shown below.\n",
      "\n",
      "--- Top matches ---\n",
      "[0.823] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.804] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.804] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.789] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.786] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.785] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.784] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.779] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.773] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "[0.772] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Top 5 pains in AI engineering and their frequency.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "Top matches shown below.\n",
      "\n",
      "--- Top matches ---\n",
      "[0.852] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.849] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.843] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.839] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.837] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.829] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "[0.823] page 15 :: most popular among these modalities. Starting with image generation: 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 16/32...\n",
      "[0.814] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.813] page 1 :: For customer facing applications, 3 out of the top 5 (and half of the top 10) most popular models are from OpenAI 70% of respondents are using RAG in some form More than 50% of folks are updating their models at least monthly Audio is poised for a major adoption wave, with 37% of respondents planning to use it soon The...\n",
      "[0.813] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Top priorities for the next 6‚Äì12 months (5 bullets).\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "Top matches shown below.\n",
      "\n",
      "--- Top matches ---\n",
      "[0.837] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.817] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.811] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.799] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.798] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.788] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.782] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.780] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.778] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.774] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. From charts, summarize 5 trends; include figure titles and pages.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "Top matches shown below.\n",
      "\n",
      "--- Top matches ---\n",
      "[0.814] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.795] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.790] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.786] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.779] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.769] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.769] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.767] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.764] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "[0.762] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Methods/survey design: N, MOE, field dates, sampling.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "Top matches shown below.\n",
      "\n",
      "--- Top matches ---\n",
      "[0.834] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.815] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.803] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.801] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.798] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.793] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.789] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.788] page 9 :: We asked the folks fine-tuning about their methods. Many folks mentioned LoRA / QLoRA, reflecting a strong preference for parameter-efficient methods. There was also a good amount of DPO and reinforcement fine- tuning. The most popular core training approach was good old supervised fine-tuning, and many hybrid approach...\n",
      "[0.781] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.778] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Podcasts/newsletters people actually learn from.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "Top matches shown below.\n",
      "\n",
      "--- Top matches ---\n",
      "[0.846] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.833] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.816] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.805] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.794] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.793] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.791] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.786] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.785] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.771] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. 150-word executive summary + 3 citations.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "Top matches shown below.\n",
      "\n",
      "--- Top matches ---\n",
      "[0.817] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.801] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.801] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.788] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.782] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.775] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.774] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.770] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "[0.769] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.767] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "\n",
      "Saved: /mnt/data/amplify_batch_narrative.csv\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. List section headings with page numbers.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.811] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.799] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.795] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.788] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.787] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.779] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.775] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.774] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.762] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "[0.760] page 15 :: most popular among these modalities. Starting with image generation: 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 16/32...\n",
      "[0.760] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.760] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "[0.755] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "[0.753] page 22 :: Storage, retrieval, and üåüvector databases üåü Where does the context live? How do we get it when we need it? 65% of respondents are using a dedicated vector database. It turns out that at the moment specialized 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/t...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Extract 7 key findings with exact % and dates.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.827] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.805] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.801] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.796] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.788] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.785] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.780] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.775] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.774] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "[0.772] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "[0.771] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.771] page 22 :: Storage, retrieval, and üåüvector databases üåü Where does the context live? How do we get it when we need it? 65% of respondents are using a dedicated vector database. It turns out that at the moment specialized 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/t...\n",
      "[0.769] page 4 :: internal and external use cases.¬† The top use cases we‚Äôre seeing overall are squarely for developers ‚Äì code generation and code intelligence ‚Äì but there‚Äôs also a good deal of writing related tasks in there too.¬† 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-post...\n",
      "[0.762] page 15 :: most popular among these modalities. Starting with image generation: 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 16/32...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. How often do teams update models? Give % weekly/monthly + reasons.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.837] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.804] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.788] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.785] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "[0.785] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.778] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.769] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.765] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.765] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "[0.764] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.763] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.759] page 15 :: The intent to adopt rate is calculated by taking the percentage of respondents who say they don‚Äôt currently but do plan to use a type of model, and dividing it by the percentage of respondents who don‚Äôt currently use a type of model in total. Essentially: audio tops the chart by a wide margin. The takeaway? Audio is ne...\n",
      "[0.759] page 1 :: For customer facing applications, 3 out of the top 5 (and half of the top 10) most popular models are from OpenAI 70% of respondents are using RAG in some form More than 50% of folks are updating their models at least monthly Audio is poised for a major adoption wave, with 37% of respondents planning to use it soon The...\n",
      "[0.759] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Compare effectiveness of LLMs vs agents; include definitions if given.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.826] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.808] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.800] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.794] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.776] page 6 :: Another important story here is heterogeneity. 94% of people using LLMs are using them for at least 2 use cases, and 82% are using them for at least 3.¬† Essentially: folks using LLMs are using them internally, externally, and across multiple use cases. 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners ...\n",
      "[0.774] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.771] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "[0.769] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.767] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.767] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.759] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.757] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "[0.751] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "[0.751] page 22 :: Storage, retrieval, and üåüvector databases üåü Where does the context live? How do we get it when we need it? 65% of respondents are using a dedicated vector database. It turns out that at the moment specialized 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/t...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. What share won‚Äôt pay more for lower latency/better reasoning? Any cuts by size?\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.847] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.838] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.826] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.818] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.817] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.812] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.811] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.808] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.804] page 6 :: Another important story here is heterogeneity. 94% of people using LLMs are using them for at least 2 use cases, and 82% are using them for at least 3.¬† Essentially: folks using LLMs are using them internally, externally, and across multiple use cases. 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners ...\n",
      "[0.803] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.789] page 22 :: Storage, retrieval, and üåüvector databases üåü Where does the context live? How do we get it when we need it? 65% of respondents are using a dedicated vector database. It turns out that at the moment specialized 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/t...\n",
      "[0.787] page 23 :: vector databases are providing enough value over general purpose ones with vector extensions. 35% said they primarily self host, while 30% primarily use a third party provider. But overall, that‚Äôs a healthy majority!¬† The (more) fun stuff 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.am...\n",
      "[0.784] page 1 :: For customer facing applications, 3 out of the top 5 (and half of the top 10) most popular models are from OpenAI 70% of respondents are using RAG in some form More than 50% of folks are updating their models at least monthly Audio is poised for a major adoption wave, with 37% of respondents planning to use it soon The...\n",
      "[0.782] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Most used tools (vector DBs/orchestration/eval) with any %.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.826] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.800] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.797] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.796] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.795] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.793] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.793] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.791] page 22 :: Storage, retrieval, and üåüvector databases üåü Where does the context live? How do we get it when we need it? 65% of respondents are using a dedicated vector database. It turns out that at the moment specialized 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/t...\n",
      "[0.781] page 23 :: vector databases are providing enough value over general purpose ones with vector extensions. 35% said they primarily self host, while 30% primarily use a third party provider. But overall, that‚Äôs a healthy majority!¬† The (more) fun stuff 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.am...\n",
      "[0.773] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "[0.771] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.771] page 9 :: We asked the folks fine-tuning about their methods. Many folks mentioned LoRA / QLoRA, reflecting a strong preference for parameter-efficient methods. There was also a good amount of DPO and reinforcement fine- tuning. The most popular core training approach was good old supervised fine-tuning, and many hybrid approach...\n",
      "[0.769] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.769] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. How do teams evaluate models (offline/online, metrics, examples)?\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.816] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.805] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.793] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "[0.789] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.787] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.769] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.768] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.768] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.767] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.764] page 21 :: We asked the same question for how they evaluate model and system accuracy. Folks are using a combination of methods, including data collection from users, benchmarking, etc. But the most popular at the end of the day is still human review. What about monitoring your own model usage? Most respondents rely on internal m...\n",
      "[0.763] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.763] page 1 :: For customer facing applications, 3 out of the top 5 (and half of the top 10) most popular models are from OpenAI 70% of respondents are using RAG in some form More than 50% of folks are updating their models at least monthly Audio is poised for a major adoption wave, with 37% of respondents planning to use it soon The...\n",
      "[0.759] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "[0.757] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Deployment targets (cloud/on-prem/edge) and motives with %.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.791] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.789] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.787] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.772] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "[0.771] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.763] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.761] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.756] page 22 :: Storage, retrieval, and üåüvector databases üåü Where does the context live? How do we get it when we need it? 65% of respondents are using a dedicated vector database. It turns out that at the moment specialized 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/t...\n",
      "[0.752] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.751] page 4 :: internal and external use cases.¬† The top use cases we‚Äôre seeing overall are squarely for developers ‚Äì code generation and code intelligence ‚Äì but there‚Äôs also a good deal of writing related tasks in there too.¬† 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-post...\n",
      "[0.749] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "[0.747] page 1 :: For customer facing applications, 3 out of the top 5 (and half of the top 10) most popular models are from OpenAI 70% of respondents are using RAG in some form More than 50% of folks are updating their models at least monthly Audio is poised for a major adoption wave, with 37% of respondents planning to use it soon The...\n",
      "[0.746] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.745] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Grounding data sources; % and challenges.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.823] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.804] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.804] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.789] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.786] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.785] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.784] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.779] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.773] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "[0.772] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.770] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "[0.768] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "[0.765] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "[0.764] page 22 :: Storage, retrieval, and üåüvector databases üåü Where does the context live? How do we get it when we need it? 65% of respondents are using a dedicated vector database. It turns out that at the moment specialized 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/t...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Top 5 pains in AI engineering and their frequency.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.852] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.849] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.843] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.839] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.837] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.829] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "[0.823] page 15 :: most popular among these modalities. Starting with image generation: 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 16/32...\n",
      "[0.814] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.813] page 1 :: For customer facing applications, 3 out of the top 5 (and half of the top 10) most popular models are from OpenAI 70% of respondents are using RAG in some form More than 50% of folks are updating their models at least monthly Audio is poised for a major adoption wave, with 37% of respondents planning to use it soon The...\n",
      "[0.813] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.813] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "[0.806] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "[0.804] page 16 :: And audio: 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 17/32...\n",
      "[0.803] page 22 :: Storage, retrieval, and üåüvector databases üåü Where does the context live? How do we get it when we need it? 65% of respondents are using a dedicated vector database. It turns out that at the moment specialized 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/t...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Top priorities for the next 6‚Äì12 months (5 bullets).\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.837] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.817] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.811] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.799] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.798] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.788] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.782] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.780] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.778] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.774] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "[0.769] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "[0.764] page 15 :: most popular among these modalities. Starting with image generation: 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 16/32...\n",
      "[0.764] page 10 :: Unsurprisingly, prompts are updated even more frequently. 70% of folks are updating their prompts at least monthly, and 1 in 10 are doing so daily.¬† 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 11/32...\n",
      "[0.760] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. From charts, summarize 5 trends; include figure titles and pages.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.814] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.795] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.790] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.786] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.779] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.769] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.769] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.767] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.764] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "[0.762] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "[0.761] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "[0.756] page 15 :: most popular among these modalities. Starting with image generation: 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 16/32...\n",
      "[0.754] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.750] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Methods/survey design: N, MOE, field dates, sampling.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.834] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.815] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.803] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.801] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.798] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.793] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.789] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.788] page 9 :: We asked the folks fine-tuning about their methods. Many folks mentioned LoRA / QLoRA, reflecting a strong preference for parameter-efficient methods. There was also a good amount of DPO and reinforcement fine- tuning. The most popular core training approach was good old supervised fine-tuning, and many hybrid approach...\n",
      "[0.781] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.778] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.777] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "[0.773] page 21 :: We asked the same question for how they evaluate model and system accuracy. Folks are using a combination of methods, including data collection from users, benchmarking, etc. But the most popular at the end of the day is still human review. What about monitoring your own model usage? Most respondents rely on internal m...\n",
      "[0.772] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "[0.769] page 22 :: Storage, retrieval, and üåüvector databases üåü Where does the context live? How do we get it when we need it? 65% of respondents are using a dedicated vector database. It turns out that at the moment specialized 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/t...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. Podcasts/newsletters people actually learn from.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.846] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.833] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.816] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.805] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.794] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.793] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.791] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.786] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.785] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.771] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "[0.767] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "[0.762] page 1 :: For customer facing applications, 3 out of the top 5 (and half of the top 10) most popular models are from OpenAI 70% of respondents are using RAG in some form More than 50% of folks are updating their models at least monthly Audio is poised for a major adoption wave, with 37% of respondents planning to use it soon The...\n",
      "[0.756] page 7 :: Using models and customizing models (prompt management, RAG, etc.) How are people actually interfacing with all of these models and customizing them to their use cases? Besides the typical few shot learning / prompting, the overwhelming answer is RAG (or retrieval augmented generation). 70% of respondents say they‚Äôre u...\n",
      "[0.756] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "\n",
      "================================================================================\n",
      "Q: Use only the provided content. Cite pages like [p#]. 150-word executive summary + 3 citations.\n",
      "\n",
      "--- Answer ---\n",
      "(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "\n",
      "--- Top matches ---\n",
      "[0.817] page 9 :: are coming out every single week. Sometimes that‚Äôs even literally true. And just as you finish integrating one, another one drops with better benchmarks and a breaking change. Accordingly, more than 50% of respondents are updating their models at least monthly, with 17% doing so weekly. 8/10/25, 3:57 PM The 2025 AI Eng...\n",
      "[0.801] page 18 :: It‚Äôs 2025, we have to talk about agents. Everyone, of course, has their own definition of what exactly an agent is. For clarity, we defined it in the survey as ‚Äúa system where the LLM controls the core decision making or workflow.‚Äù¬† Agents are still, on the whole, fairly nascent. 80% of respondents say that LLMs are wo...\n",
      "[0.801] page 31 :: wrong (and what we do instead) Thoughts Agents are just workflows, really Engineering and Infrastructure ICML 2025 Takeaways Thoughts The most overlooked part of hiring for a role: the prep Recruiting 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-...\n",
      "[0.788] page 26 :: Who knows what it will be like in a world where we don‚Äôt know if we‚Äôre being left on read, or just facing latency issues. Or how it will feel to receive the dreaded breakup message: it‚Äôs not you, it‚Äôs my algorithm. Finally, we asked folks: what is the #1 most painful thing about AI engineering today?¬† 8/10/25, 3:57 PM ...\n",
      "[0.782] page 27 :: And if you‚Äôre looking to learn more (who isn‚Äôt), we asked folks to pick the podcasts and newsletters that they actively learn something from at least once a month. Note that there‚Äôs a bit of bias here since the AI Engineering Survey is done in partnership with Latent Space. But still. 8/10/25, 3:57 PM The 2025 AI Engin...\n",
      "[0.775] page 24 :: OK, now for some more spicy stuff. We asked some rapid fire questions: It also seems like a large portion of folks don‚Äôt believe that attention is all you need. And despite major advances in reasoning models, more than 40% of respondents still aren‚Äôt willing to pay more for inference time compute.¬† Another common hot t...\n",
      "[0.774] page 2 :: Folks had a wide variety of titles, but also a wide variety of experience. Many of the most seasoned developers out there are relative newcomers to AI: of respondents with 10+ years of software experience, 45% have 3 years or fewer of AI experience. And 1 in 10 have less than 1 year of AI experience. 8/10/25, 3:57 PM T...\n",
      "[0.770] page 30 :: Authors Barr Yaron Editors Justin Gage More Writing View All 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 31/32...\n",
      "[0.769] page 19 :: use agents at all.¬† But not all agents are created (with) equal (permissions). Surprisingly, the majority of respondents with agents in production have the ability to write data, albeit with a human in the loop. And some (13%) even can take actions completely independently.¬† It will be very exciting to see where tool p...\n",
      "[0.767] page 13 :: Other modalities: audio, image, and video Audio, image, and video usage all lag text usage by significant margins. We (surprise) call this ‚Äúthe 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/the-2025-ai-engineering-report 14/32...\n",
      "[0.754] page 3 :: Right now change is the only constant, even for the veterans. Model basics: what are people actually building? Let‚Äôs start with the basics: more than half of respondents indicated they‚Äôre using LLMs for both 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/th...\n",
      "[0.751] page 1 :: access, typically with a human in the loop, and some can even take actions completely independently And there‚Äôs a lot more. So without further ado, let‚Äôs dive in.¬† Demographics / who we surveyed Who exactly is working on the engineering side of AI? The largest group of respondents described themselves as engineers, pri...\n",
      "[0.749] page 22 :: Storage, retrieval, and üåüvector databases üåü Where does the context live? How do we get it when we need it? 65% of respondents are using a dedicated vector database. It turns out that at the moment specialized 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-posts/t...\n",
      "[0.748] page 4 :: internal and external use cases.¬† The top use cases we‚Äôre seeing overall are squarely for developers ‚Äì code generation and code intelligence ‚Äì but there‚Äôs also a good deal of writing related tasks in there too.¬† 8/10/25, 3:57 PM The 2025 AI Engineering Report | Amplify Partners https://www.amplifypartners.com/blog-post...\n",
      "\n",
      "Saved: /mnt/data/amplify_batch_charts.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'question': 'Use only the provided content. Cite pages like [p#]. List section headings with page numbers.',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 26\\n}\\n]',\n",
       "  'pages_topk': [9, 26, 31, 27, 18, 2, 19, 13, 30, 15, 24, 3, 1, 22]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. Extract 7 key findings with exact % and dates.',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 26\\n}\\n]',\n",
       "  'pages_topk': [9, 31, 18, 26, 27, 19, 13, 2, 3, 30, 24, 22, 4, 15]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. How often do teams update models? Give % weekly/monthly + reasons.',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 26\\n}\\n]',\n",
       "  'pages_topk': [9, 31, 26, 7, 19, 27, 18, 24, 3, 2, 13, 15, 1, 1]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. Compare effectiveness of LLMs vs agents; include definitions if given.',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 25\\n}\\n]',\n",
       "  'pages_topk': [18, 19, 31, 9, 6, 26, 3, 24, 13, 27, 2, 7, 1, 22]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. What share won‚Äôt pay more for lower latency/better reasoning? Any cuts by size?',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 25\\n}\\n]',\n",
       "  'pages_topk': [26, 9, 27, 18, 24, 2, 19, 13, 6, 31, 22, 23, 1, 3]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. Most used tools (vector DBs/orchestration/eval) with any %.',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 25\\n}\\n]',\n",
       "  'pages_topk': [9, 27, 31, 2, 18, 19, 26, 22, 23, 7, 24, 9, 13, 1]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. How do teams evaluate models (offline/online, metrics, examples)?',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 25\\n}\\n]',\n",
       "  'pages_topk': [9, 31, 7, 19, 26, 24, 27, 13, 18, 21, 2, 1, 1, 3]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. Deployment targets (cloud/on-prem/edge) and motives with %.',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 24\\n}\\n]',\n",
       "  'pages_topk': [31, 19, 9, 7, 2, 26, 27, 22, 18, 4, 1, 1, 24, 13]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. Grounding data sources; % and challenges.',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 24\\n}\\n]',\n",
       "  'pages_topk': [9, 31, 26, 19, 18, 27, 2, 24, 1, 13, 7, 30, 3, 22]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. Top 5 pains in AI engineering and their frequency.',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 24\\n}\\n]',\n",
       "  'pages_topk': [2, 26, 27, 31, 9, 30, 15, 13, 1, 24, 1, 3, 16, 22]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. Top priorities for the next 6‚Äì12 months (5 bullets).',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 23\\n}\\n]',\n",
       "  'pages_topk': [9, 26, 31, 18, 27, 19, 2, 13, 24, 3, 30, 15, 10, 1]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. From charts, summarize 5 trends; include figure titles and pages.',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 23\\n}\\n]',\n",
       "  'pages_topk': [9, 31, 26, 18, 19, 2, 13, 27, 30, 3, 7, 15, 24, 1]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. Methods/survey design: N, MOE, field dates, sampling.',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 23\\n}\\n]',\n",
       "  'pages_topk': [9, 27, 2, 24, 31, 26, 19, 9, 18, 13, 7, 21, 1, 22]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. Podcasts/newsletters people actually learn from.',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 23\\n}\\n]',\n",
       "  'pages_topk': [27, 9, 26, 31, 13, 19, 18, 24, 2, 30, 1, 1, 7, 3]},\n",
       " {'question': 'Use only the provided content. Cite pages like [p#]. 150-word executive summary + 3 citations.',\n",
       "  'answer': '(LLM unavailable) 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\\n  quota_dimensions {\\n    key: \"model\"\\n    value: \"gemini-1.5-flash\"\\n  }\\n  quota_dimensions {\\n    key: \"location\"\\n    value: \"global\"\\n  }\\n  quota_value: 15\\n}\\n, links {\\n  description: \"Learn more about Gemini API quotas\"\\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\\n}\\n, retry_delay {\\n  seconds: 22\\n}\\n]',\n",
       "  'pages_topk': [9, 18, 31, 26, 27, 24, 2, 30, 19, 13, 3, 1, 22, 4]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"GOOGLE_API_KEY set:\", bool(os.getenv(\"GOOGLE_API_KEY\")))\n",
    "\n",
    "# q = \"Summarize the main findings of the paper.\"\n",
    "# resp = answer(q, top_k=5)\n",
    "\n",
    "# print(\"\\n--- Answer ---\")\n",
    "# print(resp[\"answer\"])\n",
    "\n",
    "# print(\"\\n--- Top matches ---\")\n",
    "# show_matches(resp[\"matches\"])\n",
    "\n",
    "questions = [\n",
    "  \"Use only the provided content. Cite pages like [p#]. List section headings with page numbers.\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. Extract 7 key findings with exact % and dates.\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. How often do teams update models? Give % weekly/monthly + reasons.\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. Compare effectiveness of LLMs vs agents; include definitions if given.\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. What share won‚Äôt pay more for lower latency/better reasoning? Any cuts by size?\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. Most used tools (vector DBs/orchestration/eval) with any %.\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. How do teams evaluate models (offline/online, metrics, examples)?\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. Deployment targets (cloud/on-prem/edge) and motives with %.\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. Grounding data sources; % and challenges.\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. Top 5 pains in AI engineering and their frequency.\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. Top priorities for the next 6‚Äì12 months (5 bullets).\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. From charts, summarize 5 trends; include figure titles and pages.\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. Methods/survey design: N, MOE, field dates, sampling.\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. Podcasts/newsletters people actually learn from.\",\n",
    "  \"Use only the provided content. Cite pages like [p#]. 150-word executive summary + 3 citations.\"\n",
    "]\n",
    "\n",
    "# Narrative-first run\n",
    "ask_many(questions, use_charts=False, top_k=10, save_csv=\"/mnt/data/amplify_batch_narrative.csv\")\n",
    "\n",
    "# If your hits are mostly charts/tables:\n",
    "ask_many(questions, use_charts=True, top_k=14, max_imgs=6, save_csv=\"/mnt/data/amplify_batch_charts.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30366060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: M:\\job hunt\\Harrisburg University Documents\\ML Project\\Kris_Naik_series_Projects\\Multimodal RAG\n"
     ]
    }
   ],
   "source": [
    "# === Where to save outputs (MD/JSON/PNG/CSV) ===\n",
    "import os\n",
    "OUTPUT_DIR = r\"M:\\job hunt\\Harrisburg University Documents\\ML Project\\Kris_Naik_series_Projects\\Multimodal RAG\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.environ[\"OUTPUT_DIR\"] = OUTPUT_DIR\n",
    "print(\"Saving to:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a35b27",
   "metadata": {},
   "source": [
    "## Saving to Location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dc2a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace your existing ask_and_save with this version (if you haven't already)\n",
    "import os, json, datetime, textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ask_and_save(question: str, use_charts: bool = False, top_k: int = 10, max_imgs: int = 6,\n",
    "                 out_dir: str | None = None, tag: str = \"run\"):\n",
    "    out_dir = out_dir or os.getenv(\"OUTPUT_DIR\", \"/mnt/data/outputs\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    fn = answer_charts_ok if use_charts else answer\n",
    "    resp = fn(question, top_k=top_k, **({\"max_imgs\": max_imgs} if use_charts else {}))\n",
    "\n",
    "    pages = []\n",
    "    for score, d in resp[\"matches\"]:\n",
    "        p = d.metadata.get(\"page\")\n",
    "        if isinstance(p, int):\n",
    "            pages.append(p)\n",
    "    top_pages = pages[:top_k]\n",
    "\n",
    "    ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    base = os.path.join(out_dir, f\"{tag}_{ts}\")\n",
    "\n",
    "    # Markdown\n",
    "    md = [\n",
    "        \"# Multimodal RAG ‚Äî Q&A\",\n",
    "        f\"**PDF:** {os.path.basename(os.getenv('PDF_PATH',''))}\",\n",
    "        f\"**Question:** {question}\",\n",
    "        \"**Answer:**\",\n",
    "        resp[\"answer\"],\n",
    "        f\"**Top pages (retrieved):** {top_pages}\",\n",
    "    ]\n",
    "    with open(base + \".md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\\n\".join(md))\n",
    "\n",
    "    # JSON\n",
    "    with open(base + \".json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"pdf\": os.path.basename(os.getenv(\"PDF_PATH\",\"\")),\n",
    "            \"question\": question,\n",
    "            \"answer\": resp[\"answer\"],\n",
    "            \"pages_topk\": top_pages\n",
    "        }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # PNG summary card\n",
    "    fig = plt.figure(figsize=(12, 7))\n",
    "    plt.axis(\"off\")\n",
    "    wrap_q = textwrap.fill(question, 95)\n",
    "    wrap_a = textwrap.fill(resp[\"answer\"][:1800], 95)\n",
    "    plt.text(0.02, 0.94, \"ReportFindings-RAG ‚Äî Q&A\", fontsize=18, weight=\"bold\")\n",
    "    plt.text(0.02, 0.88, f\"PDF: {os.path.basename(os.getenv('PDF_PATH',''))}\", fontsize=11)\n",
    "    plt.text(0.02, 0.83, \"Question:\", fontsize=13, weight=\"bold\"); plt.text(0.02, 0.79, wrap_q, fontsize=12, va=\"top\")\n",
    "    plt.text(0.02, 0.67, \"Answer:\", fontsize=13, weight=\"bold\");  plt.text(0.02, 0.63, wrap_a, fontsize=12, va=\"top\")\n",
    "    plt.text(0.02, 0.09, f\"Top pages: {top_pages}\", fontsize=11)\n",
    "    plt.text(0.02, 0.05, \"Note: Generated from retrieved PDF context only.\", fontsize=9)\n",
    "    fig.savefig(base + \".png\", dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "    print(\"Saved:\")\n",
    "    print(\" -\", base + \".md\")\n",
    "    print(\" -\", base + \".json\")\n",
    "    print(\" -\", base + \".png\")\n",
    "    return resp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765c9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
